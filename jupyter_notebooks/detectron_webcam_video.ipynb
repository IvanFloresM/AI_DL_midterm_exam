{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d97ebd",
   "metadata": {},
   "source": [
    "# AI and Deep Learning - midterm_exam (Part 2)\n",
    "\n",
    "#### Author: Ivan Flores Martinez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c6a66",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c1456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import imutils\n",
    "\n",
    "# import detectron2\n",
    "import detectron2\n",
    "\n",
    "# import detectron2 utilities\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.video_visualizer import VideoVisualizer\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84602032",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba53a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to images\n",
    "img_dir = \"E:/Pascal VOC 2012.v3-416x416.coco/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b4474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register dataset\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"pascal\", {}, \"E:/Pascal VOC 2012.v3-416x416.coco/train/_annotations.coco.json\", \"E:/Pascal VOC 2012.v3-416x416.coco/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7609c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get dataset metadata and load images\n",
    "from detectron2.data import MetadataCatalog\n",
    "pascal_metadata = MetadataCatalog.get(\"pascal\")\n",
    "dataset_dicts = DatasetCatalog.get(\"pascal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69aad511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VOC',\n",
       " 'aeroplane',\n",
       " 'bicycle',\n",
       " 'bird',\n",
       " 'boat',\n",
       " 'bottle',\n",
       " 'bus',\n",
       " 'car',\n",
       " 'cat',\n",
       " 'chair',\n",
       " 'cow',\n",
       " 'diningtable',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'motorbike',\n",
       " 'person',\n",
       " 'pottedplant',\n",
       " 'sheep',\n",
       " 'sofa',\n",
       " 'train',\n",
       " 'tvmonitor']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print classes in dataset\n",
    "MetadataCatalog.get(\"pascal\").thing_classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96eb62",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759d216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/11 18:14:01 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=21, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=80, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/11 18:14:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/11 18:14:01 d2.data.datasets.coco]: \u001b[0mLoaded 13690 images in COCO format from E:/Pascal VOC 2012.v3-416x416.coco/train/_annotations.coco.json\n",
      "\u001b[32m[04/11 18:14:01 d2.data.build]: \u001b[0mRemoved 391 images with no usable annotations. 13299 images left.\n",
      "\u001b[32m[04/11 18:14:02 d2.data.build]: \u001b[0mDistribution of instances among all 21 categories:\n",
      "\u001b[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |\n",
      "|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|\n",
      "|    VOC     | 0            |  aeroplane  | 808          |   bicycle   | 695          |\n",
      "|    bird    | 1056         |    boat     | 854          |   bottle    | 1226         |\n",
      "|    bus     | 537          |     car     | 1988         |     cat     | 1034         |\n",
      "|   chair    | 2467         |     cow     | 638          | diningtable | 618          |\n",
      "|    dog     | 1234         |    horse    | 611          |  motorbike  | 640          |\n",
      "|   person   | 13168        | pottedplant | 951          |    sheep    | 858          |\n",
      "|    sofa    | 677          |    train    | 561          |  tvmonitor  | 735          |\n",
      "|            |              |             |              |             |              |\n",
      "|   total    | 31356        |             |              |             |              |\u001b[0m\n",
      "\u001b[32m[04/11 18:14:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/11 18:14:02 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/11 18:14:02 d2.data.common]: \u001b[0mSerializing 13299 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/11 18:14:02 d2.data.common]: \u001b[0mSerialized dataset takes 4.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/11 18:14:02 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (21, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (21,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (80, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (80,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/11 18:14:03 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\.conda\\envs\\detectron\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/11 18:14:20 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 19  total_loss: 3.565  loss_cls: 2.976  loss_box_reg: 0.6098  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.00562  time: 0.2354  data_time: 0.0965  lr: 3.8962e-05  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:14:25 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 39  total_loss: 2.826  loss_cls: 2.199  loss_box_reg: 0.5925  loss_rpn_cls: 0.00722  loss_rpn_loc: 0.005323  time: 0.2281  data_time: 0.0008  lr: 7.8922e-05  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:14:29 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 59  total_loss: 1.724  loss_cls: 0.9866  loss_box_reg: 0.699  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.007588  time: 0.2288  data_time: 0.0008  lr: 0.00011888  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:14:34 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 79  total_loss: 1.464  loss_cls: 0.7579  loss_box_reg: 0.6747  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.003924  time: 0.2298  data_time: 0.0008  lr: 0.00015884  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:14:39 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 99  total_loss: 1.509  loss_cls: 0.7343  loss_box_reg: 0.7583  loss_rpn_cls: 0.004748  loss_rpn_loc: 0.007873  time: 0.2317  data_time: 0.0008  lr: 0.0001988  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:14:43 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 119  total_loss: 1.482  loss_cls: 0.7426  loss_box_reg: 0.6477  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.00551  time: 0.2297  data_time: 0.0010  lr: 0.00023876  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:14:48 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 139  total_loss: 1.393  loss_cls: 0.6946  loss_box_reg: 0.6706  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.007184  time: 0.2292  data_time: 0.0008  lr: 0.00027872  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:14:53 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 159  total_loss: 1.081  loss_cls: 0.4772  loss_box_reg: 0.6368  loss_rpn_cls: 0.002428  loss_rpn_loc: 0.00792  time: 0.2296  data_time: 0.0008  lr: 0.00031868  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:14:57 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 179  total_loss: 1.309  loss_cls: 0.6353  loss_box_reg: 0.6652  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.005864  time: 0.2301  data_time: 0.0008  lr: 0.00035864  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:02 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 199  total_loss: 1.156  loss_cls: 0.464  loss_box_reg: 0.5701  loss_rpn_cls: 0.003198  loss_rpn_loc: 0.007046  time: 0.2307  data_time: 0.0008  lr: 0.0003986  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:07 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 219  total_loss: 1.031  loss_cls: 0.4202  loss_box_reg: 0.5716  loss_rpn_cls: 0.00592  loss_rpn_loc: 0.006146  time: 0.2318  data_time: 0.0008  lr: 0.00043856  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:11 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 239  total_loss: 1.195  loss_cls: 0.5106  loss_box_reg: 0.6521  loss_rpn_cls: 0.01422  loss_rpn_loc: 0.01319  time: 0.2311  data_time: 0.0008  lr: 0.00047852  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:16 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 259  total_loss: 1.155  loss_cls: 0.4939  loss_box_reg: 0.6229  loss_rpn_cls: 0.009275  loss_rpn_loc: 0.01183  time: 0.2310  data_time: 0.0009  lr: 0.00051848  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:21 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 279  total_loss: 1.039  loss_cls: 0.4538  loss_box_reg: 0.5806  loss_rpn_cls: 0.005218  loss_rpn_loc: 0.008561  time: 0.2305  data_time: 0.0008  lr: 0.00055844  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:25 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 299  total_loss: 0.9592  loss_cls: 0.3887  loss_box_reg: 0.5819  loss_rpn_cls: 0.005582  loss_rpn_loc: 0.008472  time: 0.2306  data_time: 0.0008  lr: 0.0005984  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:30 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 319  total_loss: 0.7388  loss_cls: 0.3185  loss_box_reg: 0.428  loss_rpn_cls: 0.008686  loss_rpn_loc: 0.01195  time: 0.2303  data_time: 0.0008  lr: 0.00063836  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:35 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 339  total_loss: 1.017  loss_cls: 0.3353  loss_box_reg: 0.6093  loss_rpn_cls: 0.008295  loss_rpn_loc: 0.008332  time: 0.2304  data_time: 0.0008  lr: 0.00067832  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:39 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 359  total_loss: 0.9089  loss_cls: 0.287  loss_box_reg: 0.5436  loss_rpn_cls: 0.0062  loss_rpn_loc: 0.01186  time: 0.2303  data_time: 0.0008  lr: 0.00071828  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:44 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 379  total_loss: 0.7886  loss_cls: 0.2768  loss_box_reg: 0.4785  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.007634  time: 0.2302  data_time: 0.0008  lr: 0.00075824  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:48 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 399  total_loss: 0.7787  loss_cls: 0.2955  loss_box_reg: 0.4491  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.008764  time: 0.2302  data_time: 0.0008  lr: 0.0007982  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:53 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 419  total_loss: 0.6908  loss_cls: 0.2535  loss_box_reg: 0.4586  loss_rpn_cls: 0.006382  loss_rpn_loc: 0.004525  time: 0.2298  data_time: 0.0008  lr: 0.00083816  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:15:58 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 439  total_loss: 0.6976  loss_cls: 0.2185  loss_box_reg: 0.4509  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.006552  time: 0.2299  data_time: 0.0008  lr: 0.00087812  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:16:02 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 459  total_loss: 0.6949  loss_cls: 0.241  loss_box_reg: 0.4422  loss_rpn_cls: 0.003972  loss_rpn_loc: 0.009298  time: 0.2296  data_time: 0.0008  lr: 0.00091808  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:16:07 d2.utils.events]: \u001b[0m eta: 0:00:04  iter: 479  total_loss: 0.7622  loss_cls: 0.2356  loss_box_reg: 0.4248  loss_rpn_cls: 0.005257  loss_rpn_loc: 0.007812  time: 0.2297  data_time: 0.0008  lr: 0.00095804  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:16:12 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.6885  loss_cls: 0.3013  loss_box_reg: 0.3544  loss_rpn_cls: 0.00794  loss_rpn_loc: 0.009025  time: 0.2297  data_time: 0.0008  lr: 0.000998  max_mem: 2361M\n",
      "\u001b[32m[04/11 18:16:12 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:54 (0.2297 s / it)\n",
      "\u001b[32m[04/11 18:16:12 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:55 (0:00:01 on hooks)\n"
     ]
    }
   ],
   "source": [
    "# Import DefaultTrainer from the engine module and config file\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# Load config file\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Modify config file\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"pascal\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "# Let training initialize from model zoo\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "\n",
    "# Specify batch size, learning rate and other hyperparameters\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 500\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, enough for this dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 20  # twenty classes\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83931b6e",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8295074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to folder\n",
    "from detectron2.checkpoint import DetectionCheckpointer, Checkpointer\n",
    "checkpointer = DetectionCheckpointer(trainer, save_dir=cfg.OUTPUT_DIR)\n",
    "checkpointer.save(\"pascal\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd6bb3",
   "metadata": {},
   "source": [
    "## Load model for detection in webcam video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e47cd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "# Create predictions for test dataset\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"pascal\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739d92a",
   "metadata": {},
   "source": [
    "## Record video with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9da675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture video from webcam\n",
    "vid_capture = cv2.VideoCapture(0)\n",
    "vid_cod = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# Create output file\n",
    "output = cv2.VideoWriter(\"videos/video_raw.mp4\", vid_cod, 20.0, (640,480))\n",
    "# Record until user hits x to stop the video\n",
    "while(True):\n",
    "     # Capture each frame of webcam video\n",
    "    ret,frame = vid_capture.read()\n",
    "    cv2.imshow(\"My webcam video\", frame)\n",
    "     # Write every frame to mp4 file\n",
    "    output.write(frame)\n",
    "     # Close and break the loop after pressing \"x\" key\n",
    "    if cv2.waitKey(1) &0XFF == ord('x'):\n",
    "        break\n",
    "# close the already opened camera\n",
    "vid_capture.release()\n",
    "# close the already opened file\n",
    "output.release()\n",
    "# close the window and de-allocate any associated memory usage\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522cac9",
   "metadata": {},
   "source": [
    "# Pass video through detectron model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "278fdb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1412/1412 [05:38<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load video\n",
    "video = cv2.VideoCapture('C:/Users/USER/Videos/video_raw.mp4')\n",
    "\n",
    "# Extract video properties\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialize video writer\n",
    "video_writer = cv2.VideoWriter('C:/Users/USER/Videos/video_obj_det.mp4', fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n",
    "\n",
    "# Load saved model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "# Initialize predictor\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"pascal\", )\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Initialize visualizer\n",
    "v = VideoVisualizer(MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), ColorMode.IMAGE)\n",
    "\n",
    "# Create function to predict video frames\n",
    "def runOnVideo(video, maxFrames):\n",
    "    # Runs the predictor on every frame in the video and returns the frame with the predictions drawn.\n",
    "    readFrames = 0\n",
    "    while True:\n",
    "        hasFrame, frame = video.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "        # Get prediction results for this frame\n",
    "        outputs = predictor(frame)\n",
    "        # Make sure the frame is colored\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        # Draw a visualization of the predictions using the video visualizer\n",
    "        visualization = v.draw_instance_predictions(frame, outputs[\"instances\"].to(\"cpu\"))\n",
    "        # Convert Matplotlib RGB format to OpenCV BGR format\n",
    "        visualization = cv2.cvtColor(visualization.get_image(), cv2.COLOR_RGB2BGR)\n",
    "        # Return visualization\n",
    "        yield visualization\n",
    "        # Count number of frames\n",
    "        readFrames += 1\n",
    "        if readFrames > maxFrames:\n",
    "            break\n",
    "\n",
    "# Create a cut-off for debugging\n",
    "num_frames = 1412 # This is the max lenght of the video I took with my webcam\n",
    "\n",
    "# Enumerate the frames of the video\n",
    "for visualization in tqdm.tqdm(runOnVideo(video, num_frames), total=num_frames):\n",
    "\n",
    "    # Write to video file\n",
    "    video_writer.write(visualization)\n",
    "\n",
    "# Release resources\n",
    "video.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910138a",
   "metadata": {},
   "source": [
    "## Open two videos simultaneously with cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8bc5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import imutils\n",
    "\n",
    "# Load videos using cv\n",
    "cap1 = cv2.VideoCapture('C:/Users/USER/Videos/video_raw.mp4')\n",
    "cap2 = cv2.VideoCapture('C:/Users/USER/Videos/video_obj_det.mp4')\n",
    "# Keep streaming videos\n",
    "while cap1.isOpened() or cap2.isOpened():\n",
    "    # Capture each frame of webcam videos\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "    # Resize window for each videos.\n",
    "    frame1 = imutils.resize(frame1, width=560, height=640)\n",
    "    frame2 = imutils.resize(frame2, width=560, height=640)\n",
    "    # Make sure frame in video1 has color\n",
    "    if ret1:\n",
    "        hsv1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2HSV)\n",
    "        cv2.imshow('raw_video', frame1)\n",
    "    # Make sure frame in video3 has color\n",
    "    if ret2:\n",
    "        hsv2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)\n",
    "        cv2.imshow('video_with_predictions', frame2)\n",
    "    # Print error message if videos can not be streamed\n",
    "    if not ret1 or not ret2:\n",
    "        print('Cant read the video , Exit!')\n",
    "        break\n",
    "    # Close windows\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # Wait 1 second\n",
    "    cv2.waitKey(1)\n",
    "# Release resources\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef45aa",
   "metadata": {},
   "source": [
    "## BONUS: Train model for instace segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c789067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1412/1412 [07:02<00:00,  3.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load video\n",
    "video = cv2.VideoCapture('C:/Users/USER/Videos/video_raw.mp4')\n",
    "\n",
    "# Extract video properties\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialize video writer\n",
    "video_writer = cv2.VideoWriter('C:/Users/USER/Videos/video_segmention.mp4', fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n",
    "\n",
    "# Initialize predictor\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Initialize visualizer\n",
    "v = VideoVisualizer(MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), ColorMode.IMAGE)\n",
    "\n",
    "# Create function to predict video frames\n",
    "def runOnVideo(video, maxFrames):\n",
    "    # Runs the predictor on every frame in the video and returns the frame with the predictions drawn.\n",
    "    readFrames = 0\n",
    "    while True:\n",
    "        hasFrame, frame = video.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "        # Get prediction results for this frame\n",
    "        outputs = predictor(frame)\n",
    "        # Make sure the frame is colored\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        # Draw a visualization of the predictions using the video visualizer\n",
    "        visualization = v.draw_instance_predictions(frame, outputs[\"instances\"].to(\"cpu\"))\n",
    "        # Convert Matplotlib RGB format to OpenCV BGR format\n",
    "        visualization = cv2.cvtColor(visualization.get_image(), cv2.COLOR_RGB2BGR)\n",
    "        # Return visualization\n",
    "        yield visualization\n",
    "        # Count number of frames\n",
    "        readFrames += 1\n",
    "        if readFrames > maxFrames:\n",
    "            break\n",
    "\n",
    "# Create a cut-off for debugging\n",
    "num_frames = 1412 # This is the max lenght of the video I took with my webcam\n",
    "\n",
    "# Enumerate the frames of the video\n",
    "for visualization in tqdm.tqdm(runOnVideo(video, num_frames), total=num_frames):\n",
    "\n",
    "    # Write to video file\n",
    "    video_writer.write(visualization)\n",
    "\n",
    "# Release resources\n",
    "video.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354e1129",
   "metadata": {},
   "source": [
    "## Open two videos simultaneously with cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "127568da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import imutils\n",
    "\n",
    "# Load videos using cv\n",
    "cap1 = cv2.VideoCapture('C:/Users/USER/Videos/video_raw.mp4')\n",
    "cap2 = cv2.VideoCapture('C:/Users/USER/Videos/video_segmention.mp4')\n",
    "# Keep streaming videos\n",
    "while cap1.isOpened() or cap2.isOpened():\n",
    "    # Capture each frame of webcam videos\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "    # Resize window for each videos.\n",
    "    frame1 = imutils.resize(frame1, width=560, height=640)\n",
    "    frame2 = imutils.resize(frame2, width=560, height=640)\n",
    "    # Make sure frame in video1 has color\n",
    "    if ret1:\n",
    "        hsv1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2HSV)\n",
    "        cv2.imshow('raw_video', frame1)\n",
    "    # Make sure frame in video3 has color\n",
    "    if ret2:\n",
    "        hsv2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)\n",
    "        cv2.imshow('video_with_predictions', frame2)\n",
    "    # Print error message if videos can not be streamed\n",
    "    if not ret1 or not ret2:\n",
    "        print('Cant read the video , Exit!')\n",
    "        break\n",
    "    # Close windows\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # Wait 1 second\n",
    "    cv2.waitKey(1)\n",
    "# Release resources\n",
    "cap1.release()\n",
    "cap2.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
